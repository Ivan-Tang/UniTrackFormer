#!/usr/bin/env python3
"""
TrackML TrackFormer å®Œæ•´æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†ä»è®­ç»ƒåˆ°æµ‹è¯•ã€é¢„æµ‹ã€å¯è§†åŒ–çš„å®Œæ•´æµç¨‹ã€‚

åŠŸèƒ½æµç¨‹ï¼š
1. æ•°æ®æ¢ç´¢å’Œå¯è§†åŒ–
2. æ¨¡å‹è®­ç»ƒï¼ˆå¯é€‰ï¼Œå¦‚æœæ²¡æœ‰ç°æˆæ¨¡å‹ï¼‰
3. æ¨¡å‹æµ‹è¯•å’Œé¢„æµ‹
4. ç»“æœå¯è§†åŒ–å’Œåˆ†æ
5. æ€§èƒ½è¯„ä¼°

ç”¨æ³•ï¼š
    python demo_complete_pipeline.py [--train] [--event event000001000]
"""

import argparse
import os
import sys
import pandas as pd
import numpy as np
import torch
from datetime import datetime

# å¯¼å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡å—
from src.dataset import TrackMLDataset
from src.trackformer import create_trackformer_600mev
from src.trainer import main as train_main
from test_and_predict import TrackMLPredictor, visualize_predictions
from advanced_visualization import TrackMLVisualizer, quick_visualize_event


def check_data_availability():
    """æ£€æŸ¥æ•°æ®å¯ç”¨æ€§"""
    data_paths = {
        'train_sample': 'data/train_sample',
        'test': 'data/test',
        'detectors': 'data/detectors.csv'
    }
    
    available_data = {}
    for name, path in data_paths.items():
        if os.path.exists(path):
            if os.path.isdir(path):
                files = [f for f in os.listdir(path) if f.endswith('-hits.csv')]
                available_data[name] = len(files)
            else:
                available_data[name] = True
        else:
            available_data[name] = False
    
    return available_data


def check_model_availability():
    """æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹å¯ç”¨æ€§"""
    model_paths = [
        'checkpoints/best_model.pth',
    ]
    
    for path in model_paths:
        if os.path.exists(path):
            return path
    
    return None


def explore_data(event_id='event000001000'):
    """æ•°æ®æ¢ç´¢é˜¶æ®µ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š DATA EXPLORATION PHASE")
    print(f"{'='*60}")
    
    # æ£€æŸ¥æ•°æ®
    data_status = check_data_availability()
    print(f"ğŸ“ Data Status:")
    for name, status in data_status.items():
        if isinstance(status, bool):
            print(f"   {name}: {'âœ… Available' if status else 'âŒ Missing'}")
        else:
            print(f"   {name}: {'âœ…' if status > 0 else 'âŒ'} {status} events")
    
    if not data_status['train_sample']:
        print("âŒ No training data found. Please check data/train_sample directory.")
        return False
    
    # åŠ è½½å’Œå¯è§†åŒ–ç¤ºä¾‹äº‹ä»¶
    try:
        print(f"\nğŸ” Exploring event: {event_id}")
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = TrackMLVisualizer('results/exploration')
        
        # åŠ è½½äº‹ä»¶æ•°æ®
        from src.visual import load_event_data
        hits, truth = load_event_data('data/train_sample', event_id)
        
        print(f"   ğŸ“ˆ Event Statistics:")
        print(f"      - Total hits: {len(hits):,}")
        print(f"      - Unique volumes: {hits['volume_id'].nunique()}")
        print(f"      - Unique layers: {hits['layer_id'].nunique()}")
        
        if truth is not None:
            unique_particles = truth[truth['particle_id'] != 0]['particle_id'].nunique()
            print(f"      - True particles: {unique_particles}")
        
        # åˆ›å»ºå¯è§†åŒ–
        visualizer.plot_event_overview(hits, truth, f'{event_id}_exploration')
        print(f"   ğŸ“¸ Visualizations saved to results/exploration/")
        
        return True
        
    except Exception as e:
        print(f"âŒ Data exploration failed: {e}")
        return False


def train_or_load_model(force_train=False):
    """è®­ç»ƒæˆ–åŠ è½½æ¨¡å‹"""
    print(f"\n{'='*60}")
    print(f"ğŸ§  MODEL PREPARATION PHASE")
    print(f"{'='*60}")
    
    # æ£€æŸ¥ç°æœ‰æ¨¡å‹
    existing_model = check_model_availability()
    
    if existing_model and not force_train:
        print(f"âœ… Found existing model: {existing_model}")
        print(f"   Skipping training. Use --train to force retraining.")
        return existing_model
    
    if force_train or existing_model is None:
        print(f"ğŸ‹ï¸ Starting model training...")
        
        if existing_model is None:
            print(f"   No existing model found.")
        else:
            print(f"   Force retraining requested.")
        
        try:
            # ç¡®ä¿checkpointsç›®å½•å­˜åœ¨
            os.makedirs('checkpoints', exist_ok=True)
            
            # è¿è¡Œè®­ç»ƒ
            print(f"   ğŸ”„ Training TrackFormer model...")
            print(f"   â° This may take several minutes to hours depending on your hardware...")
            
            # è°ƒç”¨è®­ç»ƒä¸»å‡½æ•°
            train_main()
            
            # æ£€æŸ¥è®­ç»ƒç»“æœ
            model_path = 'checkpoints/best_model.pth'
            if os.path.exists(model_path):
                print(f"   âœ… Training completed successfully!")
                print(f"   ğŸ’¾ Model saved to: {model_path}")
                return model_path
            else:
                print(f"   âŒ Training completed but model not found.")
                return None
                
        except Exception as e:
            print(f"   âŒ Training failed: {e}")
            return None
    
    return existing_model


def test_and_predict_model(model_path, event_id='event000001000'):
    """æµ‹è¯•å’Œé¢„æµ‹é˜¶æ®µ"""
    print(f"\n{'='*60}")
    print(f"ğŸ”® TESTING AND PREDICTION PHASE")
    print(f"{'='*60}")
    
    try:
        print(f"ğŸ¤– Loading model: {model_path}")
        predictor = TrackMLPredictor(model_path)
        
        print(f"ğŸ¯ Predicting event: {event_id}")
        predictions = predictor.predict_event('data/train_sample', event_id)
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        result_df = predictor.save_predictions(event_id, predictions, 'results/predictions')
        print(f"ğŸ’¾ Predictions saved")
        
        # è¯„ä¼°é¢„æµ‹ç»“æœ
        print(f"ğŸ“Š Evaluating predictions...")
        metrics = predictor.evaluate_predictions(predictions)
        
        print(f"   ğŸ“ˆ Performance Metrics:")
        for metric_name, metric_value in metrics.items():
            print(f"      - {metric_name.capitalize()}: {metric_value:.3f}")
        
        return predictions, metrics
        
    except Exception as e:
        print(f"âŒ Testing and prediction failed: {e}")
        return None, None


def advanced_visualization_analysis(event_id, predictions, metrics):
    """é«˜çº§å¯è§†åŒ–å’Œåˆ†æ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ ADVANCED VISUALIZATION PHASE")
    print(f"{'='*60}")
    
    try:
        print(f"ğŸ¨ Creating comprehensive visualizations...")
        
        # åˆ›å»ºé«˜çº§å¯è§†åŒ–å™¨
        visualizer = TrackMLVisualizer('results/analysis')
        
        # åŠ è½½äº‹ä»¶æ•°æ®
        from src.visual import load_event_data
        hits, truth = load_event_data('data/train_sample', event_id)
        
        # åˆ›å»ºå®Œæ•´æŠ¥å‘Š
        visualizer.create_event_report(event_id, hits, truth, predictions, metrics)
        
        # åˆ›å»ºé¢„æµ‹å¯¹æ¯”å¯è§†åŒ–
        visualize_predictions('data/train_sample', event_id, predictions, 'results/analysis')
        
        print(f"   ğŸ“¸ Comprehensive visualizations created")
        print(f"   ğŸ“„ Detailed report saved")
        print(f"   ğŸ“ Results saved to results/analysis/")
        
        return True
        
    except Exception as e:
        print(f"âŒ Advanced visualization failed: {e}")
        return False


def generate_summary_report():
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ SUMMARY REPORT")
    print(f"{'='*60}")
    
    # æ”¶é›†æ‰€æœ‰ç»“æœæ–‡ä»¶
    result_dirs = ['results/exploration', 'results/predictions', 'results/analysis']
    
    print(f"ğŸ“ Generated Files:")
    total_files = 0
    
    for result_dir in result_dirs:
        if os.path.exists(result_dir):
            files = [f for f in os.listdir(result_dir) if f.endswith(('.png', '.csv', '.txt'))]
            if files:
                print(f"\n   ğŸ“‚ {result_dir}:")
                for file in sorted(files):
                    print(f"      - {file}")
                    total_files += 1
    
    print(f"\nğŸ“Š Summary:")
    print(f"   - Total files generated: {total_files}")
    print(f"   - Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ä¿å­˜æ€»ç»“æŠ¥å‘Š
    summary_path = 'results/pipeline_summary.txt'
    os.makedirs('results', exist_ok=True)
    
    with open(summary_path, 'w') as f:
        f.write(f"TrackML TrackFormer Complete Pipeline Summary\n")
        f.write(f"{'='*50}\n\n")
        f.write(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Total Files Generated: {total_files}\n\n")
        
        for result_dir in result_dirs:
            if os.path.exists(result_dir):
                files = [f for f in os.listdir(result_dir) if f.endswith(('.png', '.csv', '.txt'))]
                if files:
                    f.write(f"{result_dir}:\n")
                    for file in sorted(files):
                        f.write(f"  - {file}\n")
                    f.write(f"\n")
    
    print(f"ğŸ’¾ Summary report saved to: {summary_path}")


def main():
    parser = argparse.ArgumentParser(description='TrackML TrackFormer Complete Pipeline Demo')
    parser.add_argument('--train', action='store_true',
                       help='Force model training even if existing model found')
    parser.add_argument('--event', type=str, default='event000001000',
                       help='Event ID to analyze')
    parser.add_argument('--skip_exploration', action='store_true',
                       help='Skip data exploration phase')
    parser.add_argument('--skip_training', action='store_true',
                       help='Skip training phase (use existing model only)')
    parser.add_argument('--skip_prediction', action='store_true',
                       help='Skip prediction phase')
    parser.add_argument('--skip_visualization', action='store_true',
                       help='Skip advanced visualization phase')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ TrackML TrackFormer Complete Pipeline Demo")
    print(f"â° Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ Target event: {args.event}")
    
    # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
    os.makedirs('results', exist_ok=True)
    
    success_phases = []
    
    # Phase 1: æ•°æ®æ¢ç´¢
    if not args.skip_exploration:
        if explore_data(args.event):
            success_phases.append("Data Exploration")
    
    # Phase 2: æ¨¡å‹è®­ç»ƒ/åŠ è½½
    model_path = None
    if not args.skip_training:
        model_path = train_or_load_model(args.train)
        if model_path:
            success_phases.append("Model Preparation")
    else:
        model_path = check_model_availability()
        if model_path:
            print(f"âœ… Using existing model: {model_path}")
    
    # Phase 3: æµ‹è¯•å’Œé¢„æµ‹
    predictions = None
    metrics = None
    if not args.skip_prediction and model_path:
        predictions, metrics = test_and_predict_model(model_path, args.event)
        if predictions is not None:
            success_phases.append("Testing and Prediction")
    
    # Phase 4: é«˜çº§å¯è§†åŒ–
    if not args.skip_visualization and predictions is not None:
        if advanced_visualization_analysis(args.event, predictions, metrics):
            success_phases.append("Advanced Visualization")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_summary_report()
    
    # æœ€ç»ˆæ€»ç»“
    print(f"\n{'='*60}")
    print(f"ğŸ‰ PIPELINE COMPLETION")
    print(f"{'='*60}")
    
    print(f"âœ… Completed Phases: {len(success_phases)}")
    for phase in success_phases:
        print(f"   - {phase}")
    
    if len(success_phases) == 0:
        print(f"âŒ No phases completed successfully")
        sys.exit(1)
    elif len(success_phases) < 4:
        print(f"âš ï¸  Some phases were skipped or failed")
    else:
        print(f"ğŸŠ All phases completed successfully!")
    
    print(f"ğŸ“ All results saved to results/ directory")
    print(f"â° Total time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == '__main__':
    main()
